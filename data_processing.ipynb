{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client\n",
    "\n",
    "\n",
    "\n",
    "dotenv_path = Path('.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "url: str = os.getenv('SUPABASE_URL')\n",
    "key: str = os.getenv('SUPABASE_KEY')\n",
    "\n",
    "\n",
    "def init():\n",
    "    supabase = create_client(url, key)\n",
    "    return supabase\n",
    "\n",
    "def read_data():      \n",
    "      supabase = init()\n",
    "      response = supabase.table('muaban').select(\"*\").execute()\n",
    "      df_muaban = pd.DataFrame(response.data)\n",
    "      response = supabase.table('mogi').select(\"*\").execute()\n",
    "      df_mogi = pd.DataFrame(response.data)\n",
    "      response= supabase.table('rongbay').select(\"*\").execute()\n",
    "      df_rongbay = pd.DataFrame(response.data)\n",
    "      df_concatenated  = pd.concat([df_mogi, df_muaban, df_rongbay], ignore_index=True)\n",
    "      df_concatenated['id'] = range(1, len(df_concatenated) + 1)\n",
    "      return df_concatenated\n",
    "      \n",
    "df = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "created_at          0\n",
       "price               0\n",
       "area                0\n",
       "street              0\n",
       "ward              139\n",
       "district           66\n",
       "post_date           0\n",
       "num_bedroom         0\n",
       "num_diningroom      0\n",
       "num_kitchen         0\n",
       "num_toilet          0\n",
       "num_floor           0\n",
       "current_floor       0\n",
       "direction           0\n",
       "street_width        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from random import randint\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "\n",
    "with open('dags/location.json', 'r', encoding='utf-8') as file:\n",
    "    location = json.load(file)\n",
    "\n",
    "def get_district_name_by_ward(location, ward_name):\n",
    "    for district in location[\"district\"]:\n",
    "        if ward_name in district[\"wards\"]:\n",
    "            return district[\"name\"]\n",
    "    return None \n",
    "\n",
    "def get_ward_by_street(location, street_name):\n",
    "    # Duyệt qua các district trong location\n",
    "    for district in location[\"district\"]:\n",
    "        if street_name in district[\"streets\"]:\n",
    "            index = district[\"streets\"].index(street_name)\n",
    "            if index < len(district[\"wards\"]):\n",
    "                return district[\"wards\"][index]\n",
    "    return None  \n",
    "\n",
    "def get_street_by_ward(location, ward):\n",
    "    for district in location[\"district\"]:\n",
    "        if ward in district[\"wards\"]:\n",
    "            index = len(district['streets'])\n",
    "            return district[\"streets\"][randint(0, index-1)]\n",
    "        else: \n",
    "            return district[\"streets\"][randint(0, len(district['streets'])-1)]\n",
    "    return None\n",
    "\n",
    "def get_random_ward():\n",
    "    district = random.choice(location[\"district\"])\n",
    "    if district['wards']:\n",
    "        return np.random.choice(district['wards'])\n",
    "    else:\n",
    "        return \"Lò Đúc\"\n",
    "def get_random_street():\n",
    "    district = random.choice(location[\"district\"])\n",
    "    if district['streets']:\n",
    "        return np.random.choice(district['streets'])\n",
    "    else:\n",
    "        return \"Phố Lò Đúc\"\n",
    "def get_random_district():\n",
    "    return np.random.choice(location[\"district\"])['name']\n",
    "\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "# get district by ward if none return random district\n",
    "    if row['district'] == '' or pd.isnull(row['district']):\n",
    "        if row['street'] == '':\n",
    "            # get random district \n",
    "            row['district'] = get_random_district()\n",
    "        else: \n",
    "            ward = row['ward']\n",
    "            df.at[index, 'district'] = get_district_name_by_ward(location, ward)\n",
    "\n",
    "# get ward by street if none return random ward\n",
    "    if row['ward'] == '' or pd.isnull(row['ward']):\n",
    "        if row['street'] == '':\n",
    "            # get random ward \n",
    "            row['ward'] = get_random_ward()\n",
    "        else:\n",
    "            street = row['street']\n",
    "            df.at[index, 'ward'] = get_ward_by_street(location, street)\n",
    "\n",
    "# get street by ward if none return random street\n",
    "    if row['street'] == '' or pd.isnull(row['street']):\n",
    "        if row['ward'] == '':\n",
    "            row['street'] = get_random_street()\n",
    "        else: \n",
    "            ward = row['ward']\n",
    "            df.at[index, 'street'] = get_street_by_ward(location, ward)\n",
    "\n",
    "\n",
    "\n",
    "    if row['direction'] == '':\n",
    "        df.at[index, 'direction'] = 0\n",
    "\n",
    "    # if row['price'] <= 0.5:\n",
    "    #     df = df.drop(index)\n",
    "\n",
    "    # if row['area'] == 0:\n",
    "    #     df = df.drop(index)\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values\n",
    "# drop rows with missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "random_district = np.random.choice(location[\"district\"])\n",
    "print(random.choice(random_district['wards']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_values\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "data = pd.read_csv('data.csv')\n",
    "data['price_zscore'] = stats.zscore(data['price'])\n",
    "data['area_zscore'] = stats.zscore(data['area'])\n",
    "price_outliers_zscore = data[(data['price_zscore'].abs() > 0.3)]\n",
    "area_outliers_zscore = data[(data['area_zscore'].abs() > 1.36)]\n",
    "outliers_zscore = pd.concat([price_outliers_zscore, area_outliers_zscore]).drop_duplicates()\n",
    "outliers_zscore.head()\n",
    "# Remove outliers\n",
    "data = data.drop(outliers_zscore.index)\n",
    "# data = data.to_csv('data_pre.csv', index=False)\n",
    "\n",
    "# in ra các data có giá trị price thấp nhất và cao nhất tại cột area = 20 \n",
    "# data[data['area'] <= 10].sort_values(by='price', ascending=False).head(1)\n",
    "# data[data['price_zscore'].abs() >= 0.2].sort_values(by='area', ascending=True).head(20)\n",
    "#in ra các district có giá trị null\n",
    "\n",
    "# cho các district nhận giá trị ngẫu nhiên \n",
    "data['district'] = data['district'].fillna(np.random.choice(location[\"district\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['district'].isnull()].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import mlflow\n",
    "from time import strftime\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data = data.drop(columns=['id', 'created_at', 'post_date', 'current_floor', 'num_floor', 'direction', 'street_width', 'price_zscore', 'area_zscore'])\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = ['street', 'ward', 'district']\n",
    "numerical_cols = data.drop(columns=['price'] + categorical_cols).columns.tolist()\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define the models to be evaluated\n",
    "models = {\n",
    "    # \"LinearRegression\": LinearRegression(),\n",
    "    # \"Lasso\": Lasso(),\n",
    "    # \"Ridge\": Ridge(),\n",
    "    # \"ElasticNet\": ElasticNet(),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = data.drop(columns='price')\n",
    "y = data['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Iterate over each model, train it, and evaluate its performance\n",
    "for model_name, model in models.items():\n",
    "    clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('model', model)])\n",
    "    \n",
    "    # Train the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Store the model with a timestamp\n",
    "    time = strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    mlflow.sklearn.log_model(clf, f\"models/{model_name}_{time}\")\n",
    "    \n",
    "    # Preprocess test data and get predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model using mse\n",
    "    mse = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"{model_name} MAE: {mse:.2f}\")\n",
    "    \n",
    "    # Log the mse metric\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    \n",
    "    # Log the model parameters\n",
    "    mlflow.sklearn.log_model(clf, f\"models/{model_name}_{time}\")\n",
    "    \n",
    "    # Log the model performance\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    \n",
    "    # Log the model parameters\n",
    "    mlflow.sklearn.log_model(clf, f\"models/{model_name}_{time}\")\n",
    "    \n",
    "    # Log the model performance\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    \n",
    "    # Log the model parameters\n",
    "    mlflow.sklearn.log_model(clf, f\"models/{model_name}_{time}\")\n",
    "    \n",
    "    # Log the model performance\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()\n",
    "# y_test.head(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "\n",
    "#load model \n",
    "# model = mlflow.sklearn.load_model(\"mlruns/0/247ce27ff3ea4d619c4122354155f93c/artifacts/models/RandomForestRegressor_2024-05-25 08:20:05\")\n",
    "model = mlflow.sklearn.load_model(\"mlruns/0/247ce27ff3ea4d619c4122354155f93c/artifacts/models/RandomForestRegressor_2024-05-25 08:51:02\")\n",
    "#make example test\n",
    "# tạo một dữ liệu test mới khong có trong tệp dữ liệ \n",
    "\n",
    "example ={\n",
    "  \"area\": 30,\n",
    "  \"street\": \"Đại La\",\n",
    "  \"ward\":  \"Trương Định\",\n",
    "  \"district\": \"Hai Bà Trưng\",\n",
    "  \"num_bedroom\": 0,\n",
    "  \"num_diningroom\": 0,\n",
    "  \"num_kitchen\": 0,\n",
    "  \"num_toilet\": 0\n",
    "}\n",
    "example = pd.DataFrame(example, index=[0])\n",
    "\n",
    "\n",
    "model.predict(example)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
